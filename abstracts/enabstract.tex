+\begin{englishabstract}

Emulation of the human capability for natural language dialogue has been central to the enterprise of Artificial Intelligence since the very beginning of the field, going back to Alan Turing's identification of fully human-like dialogue as a litmus test for successful AI (i.e. what is now called the "Turing Test").  In recent years, natural language dialogue has also become important in the commercial AI sphere, with high profile offerings such as Apple's Siri, and Microsoft's Cortana and Xiaoice.  However, the state of the art in natural language dialogue remains far below the human level.  

There have been dramatic recent advances in many related, supporting areas of computational linguistics and AI, such as speech recognition and generation, machine translation, information retrieval, parsing, semantic analysis, sentiment and opinion mining, and many others.  In spite of this related progress, however, there have been no truly fundamental breakthroughs in the area of dialogue systems proper.  Even the best existing systems operate mainly based on surface-level linguistic cues and simple heuristics, rather than based on richly mapping and responding to the semantic and pragmatic intentions implicit in the human portions of the dialogue.  The result of these internal deficits in semantics and pragmatics are externally  manifested as dialogue performance that generally becomes tiresome to the human user after a brief period.  For example, few people currently use the Siri/Cortana/Xiaoice/etc. dialogue systems on their smartphones as their principal means of interaction with the devices, because these dialogue systems understand things sufficiently poorly that using them for most purposes is objectionably laborious, even when in principle possible.

Creating truly human-level dialogue systems is a huge project, as witnessed by the large teams and large sums of money that technology firms have recently devoted to creating dialogue systems with rather severely limited functionality.   Our goal in this thesis is not to fully solve the problem, but to lay a new conceptual and practical foundation for ongoing work.  The key hypothesis underlying our work is that, to achieve a broadly useful level of functionality (and as well to ultimately achieve a truly human-level functionality), a dialogue system must be constructed according to the following four principles:

\begin{itemize}
\item {\bf deep representation }: dialogue should be fundamentally founded on mapping natural language utterances into a rich, and flexibly manipulable, semantic representation --in which an utterance is given a "deep representation" that is largely separate from the properties of the surface-level language involved in an utterance
\item {\bf uncertain logical inference}: dialogue should involve inference that is both logical (involving inferential steps such as deduction, induction and abduction) and uncertain (encompassing e.g. probabilistic and fuzzy aspects of uncertainty)
\item {\bf foundation in speech act theory}: linguistic interactions should be understood as embedded in a larger matrix of embodied interactions --, so that each utterance is understood as a "speech act" with some uniquely linguistic properties, and some pragmatic properties that are shared by speech acts and other sorts of actions
\item {\bf motivated dialogue control}:  dialogue control (the choice of what to say when) should be founded on a model of intelligent agent motivation: the system should choose what to say based on its underlying motivations, rather than based on simple cue-response patterns
\end{itemize} 

The objective of our research has been to explore these four principles via

\begin{itemize}
\item formulating more rigorous and precise versions of these conceptual hypotheses, using appropriate formalizations and establishing connections with previous literature where appropriate
\item implementing a prototype of an embodied, motivated dialogue system, embodying reasonably fleshed-out versions of the structures implied in each of the four principles
\end{itemize}

The purpose of the prototype implementation has not been primarily to achieve impressive practical functionality, but rather to assist with clarifying the underlying concepts, and to lay a formal and conceptual foundation on which future theoretical and practical work on dialogue systems may proceed.

With the above in mind, we have designed and implemented in software a "cognitive dialogue model" that represents both linguistic and non-linguistic knowledge using a weighted, labeled hypergraph store called the Atomspace.  The Atomspace representation is relatively simple and commonsensical in nature, but also maps formally into probabilistic logic, enabling it to serve as a flexible and robust foundation for automated reasoning and learning.  Our cognitive dialogue  model works via  mapping natural language utterances into the Atomspace, which providea a medium for "deep representation" of the semantics and pragmatics of an utterance.  Probabilistic reasoning and learning, integration of linguistic and nonlinguistic knowledge, and motivated dialogue control then operate via manipulating Atomspace-based deep representations.  Language generation then occurs via reverse-mapping of cognitively-selected sub-hypergraphs of the Atomspace into natural language utterances.  We have implemented our prototype cognitive dialogue model for English, but the underlying principles are language-independent.

The major works and contributions of this thesis can be summarized as follows:


\begin{itemize}

\item We have created a comprehensive "cognitive dialogue model" embodying the four principles serving as the foundation of our investigation (deep representation, uncertain logical inference, speech act theory, motivated dialogue control)
\item Within this cognitive dialogue model, we have
\begin{itemize}
\item given a novel formulation of dialogue control in terms of Speech Act Theory and the Psi model of action selection
\item demonstrated the utilization of uncertain logical reasoning (via the Probabilistic Logic Networks logic framework) to perform commonsense logical inference from statements uttered in natural language
\item created specific  mechanisms for question-answering based on deep representations of natural language knowledge and queries, and demonstrated the utilization of these mechanisms for queries on a large common sense knowledge base (Simple English Wikipedia)
\item designed and implemented a novel framework using hypergraph pattern matching to translate the output of a dependency parser into an abstract logic formalism
\item designed and implemented a novel algorithm for surface realization, utilizing hypergraph pattern matching to generate natural language sentences corresponding to semantic hypergraphs, via leveraging knowledge obtained from sentences the system has previously interpreted
\end{itemize}

\end{itemize}

Via these specific accomplishments, we have demonstrated the theoretical and practical viability of creating natural language dialogue systems based upon the four principles of deep representation, uncertain inference, speech act theory, and motivated dialogue control.  

The research  reported here is merely the beginning of what is sure to be a long-term exploration; the long-term goal of a natural language dialogue system with full human-level functionality remains a significant way off.    However, the theoretical and practical tools created in the course of this thesis work possess value both as tools for use in real-world software applications, and as demonstrations of what kind of natural language processing it is possible to do using a framework based on the four principles with which we began.



\englishkeywords{Knowledge Representation; Language Reasoning; Dialogue System; Natural Language Comprehension; Natural Language Generation}
\end{englishabstract}
