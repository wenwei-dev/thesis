\chapter{智能会话系统中的知识表示和逻辑推理}{Knowledge Representation and Logic Inference for Cognitive Dialogue System}
\label{chap:representation}


要使计算机能理解并灵活运用人类的自然语言，将自然语言转换成一种能容易通过计算机来操作的知识表示形式是不可忽视的，这种知识表示体系不仅要满足自然语言的复杂特性，使得自然语言处理系统能在自然语言和知识表示之间相互转换，以实现人机之间的自然语言通信。同时，为了构建一个能较好的与人类沟通的智能对话系统，这种知识表示机制还需要能被应用在适当的逻辑推理系统中使其能进行必要的逻辑推理，以生成能被人类理解的智能的对话应答。

本章提出了一种能满足上述要求的基于超图的知识表示体系，阐述了该知识表示体系中的基本操作原理和基本数据类型，并从范畴论角度分析了其被应用在智能对话系统中的理论基础。本章还阐述了能被应用在这种基于超图的知识表示体系上和本文研究的智能对话中使用的逻辑推理系统----概率逻辑网络。

值得一提的是，这里介绍的知识表示体系并不仅仅是适用于自然语言处理和智能对话系统，该知识表示体系目的在于模拟人脑的知识表示方式、记忆空间以及认知过程等等，因此同样适用于其他智能处理模块。本文的研究目标之一也是通过探索智能对话系统来研究实现一个相对智能的人机交互系统。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{基于超图的知识表示方法}{Knowledge Representation Based on Hypergraph}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

对于任何以实现复杂功能为目标的自然语言处理系统（如智能对话系统或复杂的问答系统等）来说，系统内部知识如何表示是至关重要的。高效的知识表示机制不仅能使系统不同模块之间高效地传递有用的信息，更能使系统的知识库通过与用户的交互不断完善。本节主要阐述一种高效灵活的基于超图的知识表示方法，首先会解释其理论基础和相应的数据结构等，同时为了方便对本文研究工作的解释，在这一节我们还会列出一些该知识表示体系中基本的且后文经常会用到的数据类型。

\subsection{知识表示和记忆空间}{Representation and Memory}

\paragraph{本地和全局知识表示}

本文所采用的知识表示机制其本质是一个超图表示的{\it 网络}。把心智当作网络的观点其实是隐含在模式主义哲学中的，因为每一个模式都可以被看成某物的模式，或关于某物的布置的模式——因而一个模式总是可以被看做二个或更多物体之间的关系。一系列的模式形成一个模式网络。各类知识可以以网络形式来表示，而认知过程也可以被表示为网络，举例来说将它们表示为程序，以各种树或图的形式来表示。在一个智能中模式的涌现可以被看作自身的一个模式网络；在涉身的心灵和它的物理和社会环境之间的关系可以被看做某种生态和社会网络。

知识表示体系的两个主要超类是{\it 局部}（也被称为{\it 显示}）和全局（也被称为{\it 隐式}）系统，我们用一个称为{\it 全局-局部}的混合类包含了这两者。在一个{\it 局部}系统中，每一条知识都是用一小部分认知系统的元素来存储的；在一个{\it 全局}系统中，每一条知识都被以一种特定的模式存储与激活，比如以认知系统的一定比例的元素的形式；在一个{\it 全局-局部}混合系统中，这两种方式被共同使用。以上三种知识表征类型都可以被网络所实现。在本文研究的智能对话系统中，这三者都是以{\it 同样}的网络（Atomspace）来实现。

\paragraph{记忆类型和相关认知处理}

我们的知识表示体系中包含多种的记忆类型，如同上面所讨论的，它的前提是正确地建立一个类人的人工智能系统，以处理不同类型的记忆，这些记忆包括了结构化的和动态的。

该知识表示中的记忆类型有：陈述性记忆、过程性记忆、感知记忆、以及场景记忆，这些在认知科学中被广泛讨论\cite{Tulving2005}的记忆类型，以及分配泛用的系统资源的注意力记忆、和为特定目标分配系统资源的意向性记忆。这些记忆类型在一个开源的认知体系结构系统OpenCog\footnote {\url{http://wiki.opencog.org}}中被一一实现，表格\ref{tab:opencog}概述了这些记忆类型，给出了关键的引用并指出了相关的认知过程，同时指出了每一个认知过程（模式创造、联系等）所对应的泛化的模式主义认知动力学。

以模式主义认知理论的形式，上述多种记忆类型可被看做特定类型模式的特化存储方式，并经过了计算时间与空间上的优化。联系到某种特定类型的记忆的认知过程被用来创造和识别该记忆的类型。原则上所有类型的模式都可以在统一的记忆和处理构架下进行，这种类型特例化，是为了能够在现有的计算条件可接受的前提下创造有效的泛化智能。我们在\cite{Goertzel2010c}中所详细论述过，高效性并不是可有可无的，而是对真实世界中的泛化智能举足轻重的特性（就像Hutter所展示的，如果没有效率的限制，任意登记的泛化智能都可以通过简单而琐碎的程序来实现）。

这种知识表示体系的设计本质在于，与每种类型的记忆相关的数据结构和处理过程是被紧密联系在一起的，相比于仅仅包含同一种结构和处理过程的而仅仅以不同的黑盒分割开的构架，它产生了协同性的智能。我们的知识表示体系中还设计有交互的认知处理过程，以使得不同类型的记忆间可以互相转换，尽管有时这会消费较多的计算资源（比如，一段陈述性的知识可能通过一些努力被解释为过程性或场景性的知识）；同时，对于一个主要处理某一种类型记忆的学习进程来说，它可能会经常通过把知识转换成其他类型来解决问题，比如认知协同任务。

\newcolumntype{Y}[1]{>{\centering\hspace{0pt}\arraybackslash}m{#1}}

\begin{table*}[ht]
\centering
\begin{tabular}{|Y{3cm}|Y{5cm}|Y{3cm}|}
\hline \textbf{记忆类型} & \textbf{特定的认知过程} & {\bf 泛化的认知功能} \\ \hline
\textbf{陈述性} & 概率逻辑网络PLN\cite{Goertzel2008}; 概念调整\cite{Fauconnier2002} & 创建新的模式 \\ \hline
\textbf{过程性} & MOSES（一个创新的概率演化运算学习算法）\cite{Looks2006} & 创建新的模式 \\ \hline
\textbf{场景性} & 内部模拟引擎\cite{Goertzel2008d} & 关联，创建新的模式 \\ \hline
\textbf{注意性} & 注意力经济分配网络（ECAN）\cite{Goertzel2010} & 关联，评分 \\ \hline
\textbf{意向性} & 概率目标层次按照OpenPsi动机框架通过PLN和ECAN来细化\cite{Bach2009}) & 评分，创建新的模式 \\ \hline
\textbf{感知} & 视觉图像处理组件DeSTIN & 关联，注意力分配，创建新的模式，评分 \\ \hline
\end{tabular}
\caption{OpenCog中的记忆类型和认知处理过程。第三列根据模式主义理论来表示每一个特定的认知处理过程所拥有的泛化认知功能}
\label{tab:opencog} 
\end{table*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{基于超图的知识表示库AtomSpace}{Atomspace: Knowledge Representation Base via Hypergraph}
\label{sec:atoms}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

正如上述所言，Atomspace是本文所使用统一且通用的知识库，它使用包含特定类型的节点（Node）和链接（Link）的加权有向超图结构来表示知识，主要用作表示叙述性的知识，同时亦间接地表示其它类型的知识。Atomspace中使用的超图的节点和链接类型是经过包括语义层面上精挑细选得来的，以满足智能对话系统在认知过程的需要。由于Atomspace是本文研究中的知识表示核心，在这里我们会详细列出几个简单的示例予以说明。

以下是一个以Atomspace中常用的表示方法去表示继承链接（InheritanceLink）的例子：
 
{\tt\begin{small}\begin{lstlisting}
InheritanceLink Lian_Ruiting animal <.99>
\end{lstlisting}\end{small}}

\noindent 或更明确地：

 {\tt\begin{small}\begin{lstlisting}
InheritanceLink <.99>
	ConceptNode "Lian_Ruiting"
	ConceptNode "animal "
\end{lstlisting}\end{small}}

以及：

{\tt\begin{small}\begin{lstlisting}
EvaluationLink <.7>
	chase 
	ListLink
		cat
		mouse
\end{lstlisting}\end{small}}

\noindent 或更明确地：

{\tt\begin{small}\begin{lstlisting}
EvaluationLink <.7>
	PredicateNode "chase" 
	ListLink
		ConceptNode "cat"
		ConceptNode "mouse"
\end{lstlisting}\end{small}}

\noindent 正如上述示例所示，节点通常具有名称，而链接则没有，但链接可以连接一个或多个的目标，而这些目标可以是节点或链接。

综合来说，Atomspace是一个“带标记的通用超图“，这些标记可以是节点的名称或其真值等等。“超图“与一般“图“的其中一个主要不同之处在于其链接，例如ListLink或SetLink，它是可以连结两个以上的参数，而其通用性也允许这些链接与其他的链接相连，而不只局限于节点。

另一个值得注意的地方是这些节点的名称，虽然在这些示例中它们都是以英语来表示，但实际上我们的系统会在操作中通过自主学习去创造一些新的节点，而这些节点往往都与语言种类无关。

更重要的一点是， AtomSpace的知识表示形式的主要功能是提供一个灵活的方式去紧凑地表达多种相关形式的知识，并允许它们之间有交互操作。其中的“交互操作“是指，例如，一组的陈述性的知识可以跟另一组的注意力相关或程序性相关的知识相互连结，或一组在一个类别的知识可以跟另一组在其他类别的知识重叠在一起（同一链接同时有著一个陈述性相关的真值和一个注意力相关的重要值）。总而言之，只要有任何表示形式能够提供足够的灵活性来：

\begin{itemize}
\item 紧凑地表达所有在人类记忆中扮演著主导角色关键类别
\item 灵活地创建特定的副表示形式去表达在上述这些关键类别中的知识，同时又能够被迅速地改动或操纵这些知识
\item 重叠和连结不同种类的知识，包括上述这些特定的副表示形式
\end{itemize}

\noindent 以上几项都符合我们系统的整体要求。而这些Atom的表示形式已能满足此计设的总体要求，并从软件的角度来看已证明是可行的。

\subsubsection{基本的Atom种类}{Basic Atom Types}

\begin{itemize}
\item ConceptNode -- 表达任何的单元，具体或抽象但又不能以其他特定的节点种类来表达的概念
\item PredicateNode  -- 表达一个为Atom产生真值的程序（以下会有详细说明）
\item SchemaNode -- 表达一个以一个Atom产生另一个Atom的程序，或产生一些其他效果
\end{itemize}

和以下的链接：

\begin{itemize}
\item MemberLink -- 连结一个通用种类的Atom和一个ConceptNode，并拥有一个模糊真值
\item InheritanceLink -- 连结两个ConceptNodes，并拥有一个概率真值
\item SimilarityLink -- 连结两个ConceptNodes，并拥有一个概率真值
\item EvaluationLink -- 连结一个PredicateNode以及其参数
\item ExecutionLink -- 连结一个SchemaNode、其需要的参数以及其产生的输出
\begin{itemize}
\item ExecutionOutputLink -- 连结一个SchemaNode以及其输入，当遇到特定的认知程序时才会产生输出
\end{itemize}
\end{itemize}

\subsubsection{绑定程序的节点}{Grounded Procedure Nodes}

SchemaNode和PredicateNode有两种形态：已绑定和未绑定。未绑定是指系统尚未知道应该如何评定该方案，或系统将会以一连串的ExecutionOutputLinks来绑定该方案。而已绑定的会有一个特定程序的名称（目前该程序可以是C++，Scheme或Python语言编写的程序）来执行该方案。例如:

\begin{verbatim}
ExecutionOutputLink
	GroundedSchemaNode "plus.py"
	ListLink
		NumberNode "2"
		NumberNode "3"
\end{verbatim}

\noindent 当执行时，会调用Python函数“plus“来把“2“和“3“加起来，然后产生一个名为“5“的NumberNode作为其输出。

\subsection{內涵与外延的关系}{Intensional and Extensional Relationships}


我们所使用的知识库中的链接类型中亦有多种拥有继承和相似性质的链接，例如IntensionalInheritanceLink和ExtensionalInheritanceLink，其细节将会在\cite{PLN}中详述，但简而言之，以下链接的真值：

\begin{verbatim}
ExtensionalInheritanceLink A B
\end{verbatim}

\noindent 同时亦可被表示为：

\begin{verbatim}
SubsetLink A B
\end{verbatim}

\noindent 是一个条件概率$P(B|A)$。另一方面，以下链接的真值：

\begin{verbatim}
ExtensionalInheritanceLink A B
\end{verbatim}

\noindent 是一个条件概率$P(prop(B)|prop(A))$，当中$prop(X)$表示在PLN推理系统中定义的模糊集合X的属性。

\subsubsection{SatisfyingSet}{SatisfyingSet}
SatisfyingSet的算符能够表达一个集合关系的概念，而当中每一位成员都是乎合同一个述语的元素，并用Member的关係形式，以一个模糊数值（而非概率数值）来表达该元素属于一个概念的真确性。

举例来说，假设现在有“FriendOfBob“这个述语和三个元素“Jack“、“John“和“Jill“：

\begin{verbatim}
Evaluation <.7>
	FriendOfBob
	Jack

Evaluation <.6>
	FriendOfBob
	John

Evaluation <.8>
	FriendOfBob
	Jill
\end{verbatim}

根据SatisfyingSet算符的定义，我们会得出以下的Member：

\begin{verbatim}
Member <.7>
	Jack
	SatisfyingSet
		FriendOfBob

Member <.6>
	John
	SatisfyingSet
		FriendOfBob

Member <.8>
	Jill
	SatisfyingSet
		FriendOfBob
\end{verbatim}

\subsubsection{真值}{Truth Values}
\label{真值}

一个Atom的真值是用来表示一个Atom的\textit{真确性}，在某程度上是取决于Atom的类型。这个数值是以一个TruthValue物件的形式跟Atom链接在一起。一般来说我们会在Atom的表示式后以\ensuremath{<}\ensuremath{>}及一个数字来显示其真值，例如：

\begin{verbatim}
A <.4>
\end{verbatim}

來表示一個名稱为“A“的Atom的真值为.4。同样地：

\begin{verbatim}
IntensionalInheritanceLink Ben monster <.5,.9>
\end{verbatim}

\noindent 来表示一个连接著“Ben“和“monster“的IntensionalInheritance关係中有著一个.5的强度和.9确信情度。总而言之，\ensuremath{<}tv\ensuremath{>}表示著一个平均值为tv的概率分佈。这些概念和语义将会在\cite{PLN}中作详细展述。

\subsection{量词}{Quantiﬁers}  

在不明确逻辑理论中，量化过程是一个比较细微的事项。PLN包含了标準的ForAll和ThereExists的量词（使用高阶概率定义的概率真值），在处理量化过程时主要会用AverageQuantifier来建构，例如：

\begin{verbatim}
AverageQuantifier $X
        F($X)
\end{verbatim}

的真值为F(\$X)的真值的加权平均值，即是以下的总和：

\begin{verbatim}
w($X) F($X) / N
\end{verbatim}

\subsubsection{和自然语言处理相关的Atom类型}{Language-Relevant Atom Types}

接下来将会描述一些用来表达具体语言概念的Atom类型。

原则上，要处理从ASCII编译的语言资料，除了上述介绍的数据结构外就只有以下两个节点类型和一个链接类型：

\begin{itemize}
\item CharacterNode
\item CharacterInstanceNode
\item ListLink
\end{itemize}

\noindent 因而字串就可以以列表或拼接的方式来表达，例如“pig“可以以列表$(\#p, \#i, \#g)$来表达。

然而，实际上定义特定的語言Atom类型也很有帮助的，例如:

\begin{itemize}
\item  	MorphemeNode/ MorphemeInstanceNode
\item		WordNode/WordInstanceNode
\item		PhraseNode/PhraseInstanceNode
\item		SentenceNode/ SentenceInstanceNode
\item		UtteranceNode/ UtteranceInstanceNode
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{语言和超图之间的转换之范畴论观}{A Catergory-Theoretic View of Linguistic Hypergraph Transformations}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
我们的研究目标一直是探讨有关的语言现象和计算系统之间的交集，从而构建具有实用价值的自然语言处理系统，如智能对话系统。后面章节会通过介绍具体实现算法及相关应用来从语用计算语言学角度阐述本文的研究的可行性。本节主要在广泛的数学背景下，语言的范畴论来阐述其理论可行性。

\subsection{范畴论的基础知识}{Basics of Category Theory}

范畴论 \cite{LawvereSchanuel97}常被用于形式化各种数学结构中的共同特性，将这些数学结构的概念形式化成一组组对象和箭头（也称为态射）。一个范畴包括两个基本属性：对象之间的箭头可以复合 ；每个对象有一个标识箭头指向自己。对象和箭头可以是抽象的任何类型，这个简单的结构安排有着非凡的数学能力，使其能被用在探索各个领域的数学理论基础。

形式上，一个范畴包含一下内容：

\begin{itemize}
\item 一个对象类ob(C)，其中的元素称为C中的对象。
\item 一个箭头类hom(C)，其中的元素称为C中的箭头或态射。hom(a, b)中的元素f称为从a到b的态射，即$f : a \rightarrow b$
\item 一个用于操作态射复合的二元运算子$\circ$, 使得对于ob(C)中的任意三个对象a，b和c，$f : a \rightarrow b$ 和 $g : b \rightarrow c$ 的复合可记为 $g \circ f$ 或 $gf$，并且使得以下两条公理成立：

\begin{itemize}
\item 结合律：如果 $f : a \rightarrow b$, $g : b \rightarrow c$ 和 $h : c \rightarrow d$， 那么 $h \circ (g \circ f) = (h \circ g) \circ f$
\item 恒等性：对每一个对象x，存在一个恒等态射(identity morphism) $1x : x \rightarrow x$，使得任意态射 $f : a \rightarrow b$，有 $1b \circ f = f = f \circ 1a$ 
\end{itemize}
\end{itemize}

任何一个有向图都能生成一个小范畴：其中对象为有向图的节点，态射为有向图（视需要也可扩展为有向循环图）中的路径，态射的复合则为路径的串联。这样的范畴被称为由图产生出的“自由范畴”。


\subsection{语言与超图之间的转换之范畴论观}{A Category-Theoretic View of Linguistic Hypergraph Transformations}

在简单介绍范畴论的基本知识后，这一节主要解释范畴论如何能作为一个整体框架，用于形式化和解释本文研究的语言理解、生成以及逻辑推理等算法。这个形式化过程的关键便是使用基于超图的知识表示方式来做为各模块的共同知识表示框架。

首先我们来引入一个三元组（原子，时间间隔，原子状态），且称为“t-Atom”。大部分情况下，原子状态包括真值（TruthValue）和注意度（AttentionValue），以及一些恒量，如名称和类型。

那么在一定时间间隔下 $T$ ，t-Atomspace包含一组t-Atom，即 $(A,I,S)$ ，其中：

\begin{itemize}
\item 在某个时间点t，且$t \in T$，基于超图的知识表示库中存在原子A
\item I是原子 $A$的状态变化之间的时间间隔
\item S是原子A在时间间隔I期间的状态
\end{itemize}

因此给定一个T-Atomspace，就可以形成一个“活动图”（activity graph），其中图的节点为tAtom的集合，边则记录图中认知过程变化的活动（activity）。从节点$N_1$ 到节点$N_2$的边表示一个以$N_1$为输入且以$N_2$为输出的认知过程。各个认知过程组成的信息链就构成了活动图的路径。从范畴论的角度来说，tAtom的集合就是范畴中的对象，而表明认知活动过程的活动图路径就是范畴中的态射。

根据上述的理论基础，本文研究的语言和超图的转换过程可描述如下：

\begin{itemize}
\item 本文研究所使用的链语法分析器Link Parser（ 将在第 \ref{chap:comprehension}中具体介绍）将一个句子中的不同词节点之间的邻接关系转换成链语法中链（Links），从而产生一组链的集合。
\item 本文研究的语义关系抽取工作RelEx（ 将在第 \ref{chap:comprehension}中具体介绍）将上述的链集合转换成一组语义关系集合。
\item 本文研究的逻辑关系抽取工作RelEx2Logic（ 将在第 \ref{chap:comprehension}中具体介绍）将上述的语义关系集合转换成能适用于逻辑系统进行语义推理的更抽象的逻辑关系集合。
\item 本文研究所使用的逻辑推理工具概率逻辑网PLN（将在下一节中具体介绍）将上述的从自然语言中抽取到的知识与超图知识库中的其他种类的知识相关联。
\item 本文研究的基于超图模糊匹配的问答系统（ 将在第 \ref{chap:dialogue}中具体介绍）将一组原子集合映射到另一组完全匹配或者近似匹配的原子集合。
\item 本文研究的微观规划器Microplanning（ 将在第 \ref{chap:generation}中具体介绍）将一组系统想要通过自然语言清晰应答的原子集合 $S$ 分割成需要立即应答的原子集合$S_1$ 以及可能在不久的将来要应答的原子集合$S_2$。
\item 本文所采用的表层生成器SuReal（ 将在第 \ref{chap:generation}中具体介绍）将一组逻辑语义关系的原子集合转换成一组链语法关系集合即链集合，然后将链集合转换成词节点之间的邻接关系，从而生成相应的句子。
\end{itemize}

因此，广义来讲，自然语言理解、推理/匹配，以及自然语言生成的过程可以看成是可以链接成一个语言应答过程的三个态射，而这个语言应答过程则又可以看成是范畴论中的单一态射。

语言应答的质量可以通过对活动图的每一条边分配一个“成本”来量化，其中“成本”与“置信度”成反比。如果自然语言理解过程生成的结果具有较低“置信度”，那么这就会导致在自然语言生成或者语言推理过程中付出更高的“成本”。因此，从这角度来看，对话系统的目标可被视为提供一个能达到指定语用目的的最小成本应答。

在某种意义上说，从数学角度来高度概括和分析一个复杂的语言和超图之间相互转化的自然语言处理系统，实用价值有限，毕竟这样的分析并没有提供系统所需的具体转换算法也没有分析特定语言的细节和语境等。但是，这样的分析给我们提供了一个更广阔的视野，使我们能抛开语言的具体细节而站在一个更高的角度来看待自然语言处理的过程，这显然有助于我们更好地提高自然语言处理系统。通过本小节从范畴论的角度对整个自然语言处理过程的分析，我们不难发出，本文的自然语言理解、生成以及推理过程正是一系列按照适当顺序进行超图的转换过程，而这些转换过程也在智能体的认知活动中起到了重大作用。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{概率逻辑网}{Probabilistic Logic Network }
\label{sec:pln}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

将语言转换成逻辑形式的一个主要目的就是可以进行相应的逻辑推理，本文所采用的逻辑系统是概率逻辑网络（Probabilistic Logic Network，以下简称“PLN”）。 PLN是一个独特的推理系统，它嵌入了预测逻辑和传统逻辑的组合。\cite{Goertzel2008, RWR}中对PLN进行了全面具体的阐述及论证。在此我们仅简单介绍用于语言逻辑推理的基本相关知识。

PLN是一个数学和软件框架，被运用在本文研究的智能对话系统中，用于非确定推理、使概率真值与泛化逻辑推理规则的整合成为可能。具体来说，PLN包含：

\begin{itemize}
\item 一系列推理规则（例如，演绎、贝叶斯规则、变量归一化、演绎推理，等等），每一项都有一个或多个逻辑关系或词项（以Atomspace的原子Atom来表示）作为输入，并计算输出；
\item 特定的数学方程，基于合适的背景前提假设的概率值，计算结论的概率值。
\end{itemize}
PLN还涉及一条特殊的功能，评估概率值的置信度（证据的分量，或二阶的不确定性）。最后，PLN在软件中的实现需要重要的抉择，要求考虑推理规则的结构化表征、“推理控制”——这种策略要求，在每个特定的实际情况中，判断以何种顺序做何种推理。

\subsection{PLN的一个简单概述}{A Simple Overview of PLN}

PLN的关键因素是它的规则和方程式。总的来说，一个PLN规则有：

\begin{itemize}
\item 输入：一个原子集合（视规则而定，它必须满足某些要求）
\item 输出：一个原子集合
\end{itemize}

实际上，几乎在所有情况下，输出都是一个单一的原子，而输入则是一个单一的原子或者是一对原子。

特定的原形例子是演绎规则，它的输入是：

{\tt\begin{small}\begin{lstlisting}
X_Link A B
X_Link B C
\end{lstlisting}\end{small}}

输出如下：

{\tt\begin{small}\begin{lstlisting}
X_Link A C
\end{lstlisting}\end{small}}

在这里，X\_Link可以是继承性链接（InheritanceLink）、子集链接（SubsetLink）、隐含链接（ImplicationLink）或延伸隐含链接（ExtensionalImplicationLink)。

一个PLN方程与一条PLN规则同时存在，它表示了输出的非确定性真值，基于输入的非确定真值。例如，如果我们有：

{\tt\begin{small}\begin{lstlisting}
X_Link A B <sAB>
X_Link B C <sBC>
\end{lstlisting}\end{small}}



那么标准的PLN演绎规则告诉我们：

{\tt\begin{small}\begin{lstlisting}
X_Link A C <sAC>
\end{lstlisting}\end{small}}

其中： 

$$
s_{AC}=s_{AB}s_{BC}+\frac{\left(1-s_{AB}\right)\left(s_C-s_Bs_{BC}\right)}{1-s_B}
$$, $s_A$表示节点$A$的真值强度。

在这个例子中，每一个院子的非确定真值通过一个“强度”数值来给出。总的来说，PLN中的非确定真值可以有多种形式，比如：

\begin{itemize}
\item 单一的强度值，比如0.8，这表示概率或模糊真值，取决于具体的原子类型
\item （强度，置信度）对，比如（0.8，0.4）
\item （强度，数量）对，如（0.8，15）
\item 非确定的概率值，如（0.6，0.9， 0.95），这表示概率间的相互评分
\end{itemize}

\subsection{前向和后向链}{Forward and Backward Chaining}

PLN中典型的模式的使用是前向链和后向链推理。

前向链表示：

\begin{enumerate}
\item 给出一个感兴趣的原子池（列表）；
\item 应用PLN规则到这些原子上，以产生新的原子，最好也是感兴趣的；
\item 将这些新的原子加如到池中，返回步骤1。
\end{enumerate}

例子：“人是动物”和“动物会吸”是两个池中的原子。它们被演绎规则所组合，形成了结论“人会呼吸”

后向链分为两种情况，第一种：

\begin{itemize}
\item “真值查询”，给出一个原子目标，它的真值未知（或者过于不确定），以及一个原子池，按照演绎规则，通过组合池中原子，找到一种方法来评估该目标原子的真值。
\end{itemize}

例如：目标是“人是否会呼吸？”（InheritanceLink people breathe）。目标的真值通过“人是动物，动物会呼吸，因此人会呼吸”的推理来评估。

第二种：

\begin{itemize}
\item “填空查询”，给定一个目标链接（原子可以是节点或链接）以及一个或多个目标中间的变量原子，找出什么原子可以被放在变量原子的位置上，可以使目标链接获得一个高的置信度（即一个“高的真值”）。
\end{itemize}

例如：目标是“什么会呼吸”，即“继承链接\$X呼吸”……直接在原子空间中查找发现院子“继承链接 动物会呼吸”，表示空格\$X的位置上可以被填入“动物”。推理揭示“继承链接 人会呼吸”，因此空格\$X也可以被填入“人”。

又如：目标是“什么会呼吸和加法”，即“(InheritanceLink \$X breathe) AND (InheritanceLink \$X add)”。推理揭示此处\$X可以被填入“人”但不能是“猫”或“电脑”。

常识推理可能涉及一个前向和后向链的组合。

推理中最困难的部分是“推理控制”——在可能的推理步骤中选取哪些步骤，以获得需求的信息（在后向推理中）或获得感兴趣的新信息（在前向推理中）。在一个有大量原子的原子空间中有许多可能的和强大的启发信息需要进行选择。推理控制的最佳指导是某些基于系统的过去推理历史的归纳。当然，一个较信的系统不会有很多的历史信息。依靠非直接的相关历史是一个推理问题——这个问题的最好解决是让系统有一些历史经验。

\subsection{一阶概率逻辑网络}{First Order Probabilistic Logic Networks}

我们将在这一小节中更具体介绍PLN。PLN被氛围一阶和高阶子理论（FOPLN和HOPLN）。这些词项源自NARS\cite{Wang2006}。我们首先使用了FOPLN，然后他们使用了HOPLN。

FOPLN是一个传统逻辑，设计到词项和词项间的关系（链接）。它是一个非确定逻辑，词项和关系都拥有真值对象，真值对象有多种可能的类型，从单一的数值到复合的结构如非确定概率。词项可以是基本的观察，或一个符号集合$T$中的抽象的符号。

\paragraph{核心FOPLN关系}

“核心FOPLN”涉及集合中的关系：否定、继承、概率合取和析取、成员和模糊合取和析取。基本观察只能有成员链接，而标志词项可以有任何类型的链接。PLN通过链接不同类型的语义来清晰地区分概率关系和模糊集合关系。成员语义通常是模糊关系（尽管它们可能是脆弱的（crisp？），而继承关系是概率性的，并且有规则来管理这二者的互操作。

假定一个虚拟的主体对一个命叫Fluffy的生物做了一次基本的视角观察$o$。这个主体可能将$o$以0.9的隶属度划于“毛茸茸的”模糊集合下，也可能以0.8的隶属度将之划于“动物”的模糊集合下，于是该主体可以在记忆中建立以下链接：

 \begin{tabbing}
\=Member $o$ furry $<0.9>$\\
\>Member $o$ animals $<0.8>$\\
\end{tabbing}

随后，该主体可能想要通过合并这些链接来完善它的知识。使用最小化的模糊合取操作，该主体可能会总结出：

 \begin{tabbing}
fuz\=zyAND\ $<0.8>$\\
\> Member $o$ furry \\
\> Member $o$ animals \\
\end{tabbing}

这表示对$o$的观察结果是一个“毛茸茸的”“动物”对象。

（延伸）继承关系的语义与成员关系完全不同，尽管它们是相关的。延伸继承（ExtensionalInheritance）表征一个纯粹的条件概率子集关系，通过子集关系来表达。如果$A$是“毛茸茸的”而$B$属于“猫”集合，那么以下陈述：

\begin{tabbing}
Sub\=set $<0.9>$\\
\>A\\
\>B\\
\end{tabbing}

意思是：$$P(x \mbox{ 属于集合}\ B\vert x \mbox{ 属于集合}\ A) = 0.9.$$ 

\subsection{PLN 真值}{PLN Truth Values}

为了增加全概率析取的信息量，PLN 拥有一系列不同的真值类型：

\begin{itemize}
\item 强度真值，包含单一数值；例如，$<s>$或$<0.8>$。强度真值通常表示概率，但不总是这样。
\item 单一真值，包括一对数字。这些数字对以以下形式存在：$<s,\ w>$，$s$是一个强度值而$w$是一个“证据的权重值”；$<s,\ N>$，其中$N$是一个“计数”。“证据的权重值”是对信念的量化描述，而“计数”是对重复性证据的量化描述。
\item 非确定性真值，它用区间$[L,U]$、评分水平$b$、以及一个整数$k$来量化对真值的描述。非确定性真值量化了以下的想法：在经过了$k$次观察以后，以概率$b$的可能性，推理的结论会落在区间$[L,U]$中。
\item 分布真值，对整个概率分布的离散化近似。
\end{itemize}

\paragraph{附加的FOPLN关系}

在FOPLN核心关系之上，FOPLN还有两类额外的关系类型。有一类简单的类型，相似度，定义如下：

$$
Similarity \ A \ B
$$

如果$R \ A \ B$ 的真值可以仅仅用核心FOPLN关系中A和B的关系来计算的话，我们把关系$R$叫做简单的。而有一类复杂的“附加”关系，如意向继承（见附录\ref{app:poss_worlds}），描述了与某一词项相关联的模式的属性集合与相应的其他属性集合之间的关系。

回到我们的例子上来，主体可能观察到“猫”的两项属性，即“毛皮”和“会叫”。由于希腊神话中的三头狗Fluffy也是皮毛动物，主体可能会认为：

{\tt\begin{small}\begin{lstlisting}
IntensionalInheritance <0.5>
	Fluffy  
	cat
\end{lstlisting}\end{small}}

意思是Fluffy拥有50\%的猫的属性。为了更深入地构建这种关系，PLN还有一个混合的意向/延伸继承关系，简单地通过如子集和意向继承关系的析取来定义。

如例子所陈述，对一个一个复杂的附加关系$R$，$R \ A \ B$的真值是通过一个数值所表达的FOPLN中不同词项的关系的真值来定义的（而不是“$A$而且$B$”），它通过某个特定的数学方程来计算。

\subsection{PLN规则和方程}{PLN Rules and Formulas}

PLN中一个析取是通过规则和方程来达到的。PLN逻辑推理以“三段论演绎规则”的形式进行，以通过合并陈述和匹配的词项来寻找模式。PLN的规则包括但不限于以下例子：

\begin{itemize}
\item deduction $\left((A\rightarrow B) \wedge (B\rightarrow C) \Rightarrow (A\rightarrow C)\right)$,
\item induction $\left((A\rightarrow B) \wedge (A\rightarrow C) \Rightarrow
(B\rightarrow C)\right)$,
\item abduction $\left((A\rightarrow C) \wedge (B\rightarrow C) \Rightarrow
(A\rightarrow C)\right)$,
  \item revision, which merges two versions of the same logical relationship that have different truth values
\item inversion $\left((A\rightarrow B) \Rightarrow
  (B\rightarrow A)\right)$.
\end{itemize}

这些规则的前四项的基本设计如图\ref{fig:inference}所示。我们可以看到前三项规则表示了在三个相关联的词项上做推理的规则，同时还可以看到，归纳和回溯可以从演绎和反向的组合中获得，这是PLN真值公式使用的一项规则。

\begin{figure}[htb]
  \center
  \includegraphics[width=11cm]{figures/inference.png}
  \caption{The four most basic first-order PLN inference rules}
  \label{fig:inference}
\end{figure}

每一项规则都与一个公式相关，它应用规则以计算出真值。例如，假设$s_A$, $s_B$, $s_C$, $s_{AB}$, 以及 $s_{BC}$分别表示词项$A$、$B$、$C$以及关系$A\rightarrow B$和$B\rightarrow C$的真值，那么，在合适的条件下，演绎规则的公式如下：

$$s_{AC}=s_{AB}s_{BC}+\frac{\left(1-s_{AB}\right)\left(s_C-s_Bs_{BC}\right)}{1-s_B},$$

其中$s_{AC}$表示关系$A\rightarrow C$的真值，这个公式的前提是，假设$A\rightarrow B$和$B\rightarrow C$是相互独立的。

对于仅仅与模糊操作相关的推理，PLN的缺省版本使用带最小值/最大值公式的标准模糊逻辑（尽管还可能有与整体的PLN框架保持一致的变化）。最后，符合并模糊和概率操作的语义在\cite{Goertzel2008} 中有按时，但在\cite{Goertzel2010e}中有更严格的论证，给出了精确的的语义以构建以下形式；

$$
\textit{Inheritance} \ A \  B
$$，其中$A$和$B$由前述的成员关系$\textit{Member}\ C\ A$, $\textit{Member}\ D\ B$等给出。

显而易见，在一个清晰的情况下，所有的成员链接和继承链接的强度都是$0$或$1$，FOPLN就退化成标准的谓词逻辑。当继承是清晰的但成员关系不是的时候，FOPLN退化成高阶模糊逻辑（包括词项的模糊表述、以及模糊表述本身的模糊表述，等等）。


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{本章小结}{Summary of Accomplishments and Future Work}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
本章主要阐述新颖的并用于智能对话系统中的基于超图的知识表示方法及其灵活性和高效性；以及用于智能对话中的逻辑推理系统概率逻辑网PLN；并从范畴论角度高度概括分析了本文研究的大致框架。本文根据本章阐述的相关理论知识设计并实现了一个基于超图的语言逻辑推理系统，由于该系统依赖与未来章节要介绍自然语言理解系统，因此我们将会在第 \ref{chap:reasoning}章中具体介绍并给出相应的推理实例。
